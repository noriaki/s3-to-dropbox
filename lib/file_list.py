"""
ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆç”Ÿæˆã‚’æä¾›ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import os
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Tuple
import logging
import humanize


class FileListGenerator:
    """ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆãƒ»READMEç”Ÿæˆã‚’æä¾›ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self, logger: Optional[logging.Logger] = None):
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆç”Ÿæˆã®åˆæœŸåŒ–

        Args:
            logger: ãƒ­ã‚¬ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        self.logger = logger or logging.getLogger(__name__)

    def generate_tree_structure(self, directory: str, prefix: str = "", max_depth: int = 10,
                                current_depth: int = 0) -> List[str]:
        """
        ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ„ãƒªãƒ¼æ§‹é€ ã‚’ç”Ÿæˆ

        Args:
            directory: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
            prefix: ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ï¼ˆå†å¸°ç”¨ï¼‰
            max_depth: æœ€å¤§æ·±åº¦
            current_depth: ç¾åœ¨ã®æ·±åº¦

        Returns:
            List[str]: ãƒ„ãƒªãƒ¼æ§‹é€ ã®è¡Œãƒªã‚¹ãƒˆ
        """
        if current_depth >= max_depth:
            return [f"{prefix}...ï¼ˆæ·±ã™ãã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ï¼‰"]

        try:
            entries = []
            items = sorted(os.listdir(directory))

            for i, item in enumerate(items):
                item_path = os.path.join(directory, item)
                is_last = i == len(items) - 1

                # ãƒ„ãƒªãƒ¼è¨˜å·
                connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                extension = "    " if is_last else "â”‚   "

                if os.path.isdir(item_path):
                    entries.append(f"{prefix}{connector}{item}/")
                    # å†å¸°çš„ã«ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‡¦ç†
                    sub_entries = self.generate_tree_structure(
                        item_path,
                        prefix + extension,
                        max_depth,
                        current_depth + 1
                    )
                    entries.extend(sub_entries)
                else:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’å–å¾—
                    try:
                        size = os.path.getsize(item_path)
                        size_str = humanize.naturalsize(size, binary=True)
                        entries.append(f"{prefix}{connector}{item} ({size_str})")
                    except:
                        entries.append(f"{prefix}{connector}{item}")

            return entries

        except Exception as e:
            self.logger.error(f"ãƒ„ãƒªãƒ¼æ§‹é€ ã®ç”Ÿæˆã«å¤±æ•—: {str(e)}")
            return []

    def collect_file_info(self, directory: str) -> List[Tuple[str, int, str]]:
        """
        ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’åé›†

        Args:
            directory: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹

        Returns:
            List[Tuple[str, int, str]]: (ç›¸å¯¾ãƒ‘ã‚¹, ã‚µã‚¤ã‚º, æœ€çµ‚æ›´æ–°æ—¥æ™‚)ã®ãƒªã‚¹ãƒˆ
        """
        file_info = []

        try:
            for root, dirs, files in os.walk(directory):
                for file in files:
                    file_path = os.path.join(root, file)
                    rel_path = os.path.relpath(file_path, directory)

                    try:
                        size = os.path.getsize(file_path)
                        mtime = os.path.getmtime(file_path)
                        mtime_str = datetime.fromtimestamp(mtime).strftime('%Y-%m-%d %H:%M:%S')

                        file_info.append((rel_path, size, mtime_str))
                    except Exception as e:
                        self.logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—å¤±æ•—: {file_path} - {str(e)}")

            return sorted(file_info)

        except Exception as e:
            self.logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®åé›†ã«å¤±æ•—: {str(e)}")
            return []

    def generate_file_list_md(self, directory: str, bucket_name: str,
                             output_path: str) -> bool:
        """
        file_list.mdã‚’ç”Ÿæˆ

        Args:
            directory: ã‚¹ã‚­ãƒ£ãƒ³å¯¾è±¡ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            bucket_name: ãƒã‚±ãƒƒãƒˆå
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            bool: æˆåŠŸã—ãŸå ´åˆTrue
        """
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’åé›†
            file_info = self.collect_file_info(directory)

            # çµ±è¨ˆæƒ…å ±
            total_files = len(file_info)
            total_size = sum(size for _, size, _ in file_info)
            total_size_str = humanize.naturalsize(total_size, binary=True)

            # ãƒ„ãƒªãƒ¼æ§‹é€ ã‚’ç”Ÿæˆ
            tree_lines = self.generate_tree_structure(directory)

            # Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(f"# {bucket_name} ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§\n\n")
                f.write(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files:,}\n")
                f.write(f"ç·ã‚µã‚¤ã‚º: {total_size_str}\n\n")

                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
                f.write("## ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ \n\n")
                f.write("```\n")
                f.write(f"{bucket_name}/\n")
                for line in tree_lines:
                    f.write(f"{line}\n")
                f.write("```\n\n")

                # ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°ãƒªã‚¹ãƒˆ
                f.write("## ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°ãƒªã‚¹ãƒˆ\n\n")
                f.write("| ãƒ‘ã‚¹ | ã‚µã‚¤ã‚º | æœ€çµ‚æ›´æ–°æ—¥æ™‚ |\n")
                f.write("|------|--------|-------------|\n")

                for path, size, mtime in file_info:
                    size_str = humanize.naturalsize(size, binary=True)
                    # ãƒ‘ã‚¹ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
                    path_escaped = path.replace("|", "\\|")
                    f.write(f"| {path_escaped} | {size_str} | {mtime} |\n")

            self.logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {output_path}")
            return True

        except Exception as e:
            self.logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆç”Ÿæˆã«å¤±æ•—: {str(e)}")
            return False

    def generate_readme_md(self, bucket_name: str, output_path: str,
                          bucket_info: dict, compression_info: dict) -> bool:
        """
        README.mdã‚’ç”Ÿæˆ

        Args:
            bucket_name: ãƒã‚±ãƒƒãƒˆå
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            bucket_info: ãƒã‚±ãƒƒãƒˆæƒ…å ±ï¼ˆregion, created_dateç­‰ï¼‰
            compression_info: åœ§ç¸®æƒ…å ±ï¼ˆformat, files, splitç­‰ï¼‰

        Returns:
            bool: æˆåŠŸã—ãŸå ´åˆTrue
        """
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(f"# {bucket_name} ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—\n\n")

                # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æƒ…å ±
                f.write("## ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æƒ…å ±\n\n")
                f.write(f"- **ãƒã‚±ãƒƒãƒˆå**: {bucket_name}\n")
                f.write(f"- **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"- **å…ƒã®S3ãƒªãƒ¼ã‚¸ãƒ§ãƒ³**: {bucket_info.get('region', 'unknown')}\n")
                f.write(f"- **ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {bucket_info.get('object_count', 0):,}\n")

                original_size = bucket_info.get('original_size', 0)
                compressed_size = compression_info.get('total_size', 0)

                f.write(f"- **å…ƒã®ç·ã‚µã‚¤ã‚º**: {humanize.naturalsize(original_size, binary=True)}\n")
                f.write(f"- **åœ§ç¸®å¾Œã‚µã‚¤ã‚º**: {humanize.naturalsize(compressed_size, binary=True)}\n")

                if original_size > 0:
                    compression_ratio = (compressed_size / original_size) * 100
                    f.write(f"- **åœ§ç¸®ç‡**: {compression_ratio:.1f}%\n")

                f.write("\n")

                # åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
                f.write("## åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±\n\n")

                compression_format = compression_info.get('format', 'zip')
                files = compression_info.get('files', [])
                is_split = len(files) > 1

                if is_split:
                    f.write(f"âš ï¸ **æ³¨æ„**: ã“ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯{len(files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ†å‰²ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n")
                    f.write("### åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§\n\n")
                    for i, file_path in enumerate(files, 1):
                        file_name = os.path.basename(file_path)
                        f.write(f"{i}. `{file_name}`\n")
                    f.write("\n")
                else:
                    file_name = os.path.basename(files[0]) if files else "unknown"
                    f.write(f"- **ãƒ•ã‚¡ã‚¤ãƒ«å**: `{file_name}`\n")
                    f.write(f"- **åœ§ç¸®å½¢å¼**: {compression_format}\n\n")

                # è§£å‡æ–¹æ³•
                f.write("## è§£å‡æ–¹æ³•\n\n")

                if is_split:
                    # åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã®çµåˆãƒ»è§£å‡æ–¹æ³•
                    base_name = os.path.basename(files[0]).replace('.001', '') if files else "archive"

                    f.write("### ğŸ–¥ï¸ macOS / Linux\n\n")
                    f.write("```bash\n")
                    f.write("# 1. å…¨ã¦ã®åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®\n\n")
                    f.write("# 2. åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ\n")
                    f.write(f"cat {base_name}.* > {base_name}\n\n")
                    f.write("# 3. è§£å‡\n")
                    if compression_format == 'zip':
                        f.write(f"unzip {base_name}\n")
                    else:  # tar.gz
                        f.write(f"tar -xzf {base_name}\n")
                    f.write("```\n\n")

                    f.write("### ğŸªŸ Windows (PowerShell)\n\n")
                    f.write("```powershell\n")
                    f.write("# 1. å…¨ã¦ã®åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®\n\n")
                    f.write("# 2. åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ\n")
                    f.write(f"Get-Content {base_name}.* -Raw | Set-Content {base_name} -Encoding Byte\n\n")
                    f.write("# 3. è§£å‡ï¼ˆ7-ZipãŒå¿…è¦ï¼‰\n")
                    if compression_format == 'zip':
                        f.write(f"7z x {base_name}\n")
                    else:  # tar.gz
                        f.write(f"7z x {base_name}\n")
                    f.write("```\n\n")

                else:
                    # é€šå¸¸ã®è§£å‡æ–¹æ³•
                    file_name = os.path.basename(files[0]) if files else "archive.zip"

                    f.write("### ğŸ–¥ï¸ macOS / Linux\n\n")
                    f.write("```bash\n")
                    if compression_format == 'zip':
                        f.write(f"unzip {file_name}\n")
                    else:  # tar.gz
                        f.write(f"tar -xzf {file_name}\n")
                    f.write("```\n\n")

                    f.write("### ğŸªŸ Windows\n\n")
                    if compression_format == 'zip':
                        f.write("1. ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å³ã‚¯ãƒªãƒƒã‚¯\n")
                        f.write("2. ã€Œã™ã¹ã¦å±•é–‹ã€ã‚’é¸æŠ\n")
                        f.write("3. å±•é–‹å…ˆã‚’æŒ‡å®šã—ã¦å®Ÿè¡Œ\n\n")
                    else:  # tar.gz
                        f.write("7-Zipãªã©ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨:\n\n")
                        f.write("```cmd\n")
                        f.write(f"7z x {file_name}\n")
                        f.write("```\n\n")

                # ãã®ä»–ã®æƒ…å ±
                f.write("## ãã®ä»–ã®æƒ…å ±\n\n")
                f.write("### file_list.md ã«ã¤ã„ã¦\n\n")
                f.write("ã“ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ã¯ `file_list.md` ãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚\n")
                f.write("ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ä»¥ä¸‹ã®æƒ…å ±ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™:\n\n")
                f.write("- ãƒã‚±ãƒƒãƒˆå†…ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ï¼ˆãƒ„ãƒªãƒ¼è¡¨ç¤ºï¼‰\n")
                f.write("- å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°ãƒªã‚¹ãƒˆï¼ˆãƒ‘ã‚¹ã€ã‚µã‚¤ã‚ºã€æœ€çµ‚æ›´æ–°æ—¥æ™‚ï¼‰\n\n")

                f.write("### æ³¨æ„äº‹é …\n\n")
                f.write("- è§£å‡ã«ã¯ååˆ†ãªãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãŒå¿…è¦ã§ã™\n")
                f.write(f"- æ¨å¥¨ç©ºãå®¹é‡: {humanize.naturalsize(original_size * 1.2, binary=True)} ä»¥ä¸Š\n")
                if is_split:
                    f.write("- åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã¯å…¨ã¦åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„\n")
                    f.write("- åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ãŒ1ã¤ã§ã‚‚æ¬ ã‘ã¦ã„ã‚‹ã¨è§£å‡ã§ãã¾ã›ã‚“\n")

                f.write("\n---\n\n")
                f.write("*ã“ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯ S3-to-Dropbox ãƒ„ãƒ¼ãƒ«ã§ä½œæˆã•ã‚Œã¾ã—ãŸ*\n")

            self.logger.info(f"READMEã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {output_path}")
            return True

        except Exception as e:
            self.logger.error(f"READMEç”Ÿæˆã«å¤±æ•—: {str(e)}")
            return False
