#!/usr/bin/env python3
"""
ãƒ„ãƒ¼ãƒ«1: S3ãƒã‚±ãƒƒãƒˆæƒ…å ±ç¢ºèªãƒ„ãƒ¼ãƒ«

å…¨S3ãƒã‚±ãƒƒãƒˆã®ã‚µã‚¤ã‚ºã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°ã€ãƒªãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã‚’åé›†ãƒ»è¡¨ç¤ºã—ã¾ã™ã€‚
"""

import sys
import os
import json
import argparse
from datetime import datetime
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from lib.logger import setup_logger, log_exception
from lib.aws_client import AWSClient
from dotenv import load_dotenv
import humanize
from tqdm import tqdm


def format_size(size_bytes: int) -> str:
    """ãƒã‚¤ãƒˆæ•°ã‚’äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›"""
    return humanize.naturalsize(size_bytes, binary=True)


def print_table_header():
    """ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¡¨ç¤º"""
    print("\n" + "=" * 120)
    print(f"{'No.':<5} {'ãƒã‚±ãƒƒãƒˆå':<40} {'ãƒªãƒ¼ã‚¸ãƒ§ãƒ³':<20} {'ä½œæˆæ—¥':<12} "
          f"{'ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°':>12} {'ã‚µã‚¤ã‚º':>15}")
    print("=" * 120)


def print_bucket_row(index: int, bucket_name: str, region: str, created_date: str,
                    object_count: int, size: int):
    """ãƒã‚±ãƒƒãƒˆæƒ…å ±ã®è¡Œã‚’è¡¨ç¤º"""
    size_str = format_size(size)
    print(f"{index:<5} {bucket_name:<40} {region:<20} {created_date:<12} "
          f"{object_count:>12,} {size_str:>15}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # å¼•æ•°ãƒ‘ãƒ¼ã‚µãƒ¼
    parser = argparse.ArgumentParser(
        description='S3ãƒã‚±ãƒƒãƒˆã®æƒ…å ±ã‚’åé›†ãƒ»è¡¨ç¤ºã—ã¾ã™',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # å…¨ãƒã‚±ãƒƒãƒˆã®æƒ…å ±ã‚’è¡¨ç¤º
  python tools/bucket_info.py

  # ç‰¹å®šã®AWSãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
  python tools/bucket_info.py --profile myprofile

  # è©³ç´°ãƒ­ã‚°ã‚’å‡ºåŠ›
  python tools/bucket_info.py --log-level DEBUG
        """
    )

    parser.add_argument('--profile', type=str, help='AWSãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å')
    parser.add_argument('--log-level', type=str, default='INFO',
                       choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                       help='ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: INFOï¼‰')
    parser.add_argument('--output', type=str, default='data/bucket_info.json',
                       help='å‡ºåŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: data/bucket_info.jsonï¼‰')

    args = parser.parse_args()

    # ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
    load_dotenv()

    # ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
    logger = setup_logger('bucket_info', args.log_level)

    try:
        print("\nğŸ” S3ãƒã‚±ãƒƒãƒˆæƒ…å ±ç¢ºèªãƒ„ãƒ¼ãƒ«")
        print("=" * 120)

        # AWSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        logger.info("AWSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã¦ã„ã¾ã™...")
        aws_client = AWSClient(profile_name=args.profile, logger=logger)

        # ãƒã‚±ãƒƒãƒˆãƒªã‚¹ãƒˆã®å–å¾—
        logger.info("ãƒã‚±ãƒƒãƒˆãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¦ã„ã¾ã™...")
        buckets = aws_client.list_buckets()

        if not buckets:
            print("\nâš ï¸  ãƒã‚±ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return

        print(f"\nğŸ“¦ {len(buckets)}å€‹ã®ãƒã‚±ãƒƒãƒˆã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚æƒ…å ±ã‚’åé›†ä¸­...\n")

        # ãƒã‚±ãƒƒãƒˆæƒ…å ±ã®åé›†
        bucket_info_list = []
        total_size = 0
        total_objects = 0
        large_buckets = 0  # 10GBè¶…ãˆã‚‹ãƒã‚±ãƒƒãƒˆã®æ•°
        split_threshold = 10 * 1024 * 1024 * 1024  # 10GB

        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
        with tqdm(total=len(buckets), desc="ãƒã‚±ãƒƒãƒˆæƒ…å ±åé›†", unit="bucket") as pbar:
            for bucket in buckets:
                bucket_name = bucket['Name']
                created_date = bucket['CreationDate'].strftime('%Y-%m-%d')

                pbar.set_description(f"å‡¦ç†ä¸­: {bucket_name[:30]}")

                try:
                    # ãƒªãƒ¼ã‚¸ãƒ§ãƒ³å–å¾—
                    region = aws_client.get_bucket_region(bucket_name)

                    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†çŠ¶æ…‹
                    versioning = aws_client.get_bucket_versioning(bucket_name)

                    # ã‚µã‚¤ã‚ºã¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°
                    size, count = aws_client.get_bucket_size_and_count(bucket_name)

                    bucket_info = {
                        'name': bucket_name,
                        'region': region,
                        'created_date': created_date,
                        'object_count': count,
                        'size_bytes': size,
                        'size_human': format_size(size),
                        'versioning_enabled': versioning
                    }

                    bucket_info_list.append(bucket_info)

                    total_size += size
                    total_objects += count

                    if size > split_threshold:
                        large_buckets += 1

                except Exception as e:
                    log_exception(logger, f"ãƒã‚±ãƒƒãƒˆ {bucket_name} ã®æƒ…å ±å–å¾—ã«å¤±æ•—", e)
                    bucket_info_list.append({
                        'name': bucket_name,
                        'region': 'unknown',
                        'created_date': created_date,
                        'object_count': 0,
                        'size_bytes': 0,
                        'size_human': 'N/A',
                        'versioning_enabled': False,
                        'error': str(e)
                    })

                pbar.update(1)

        # ã‚µã‚¤ã‚ºé †ã«ã‚½ãƒ¼ãƒˆ
        bucket_info_list.sort(key=lambda x: x['size_bytes'], reverse=True)

        # ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º
        print_table_header()

        for i, info in enumerate(bucket_info_list, 1):
            print_bucket_row(
                i,
                info['name'],
                info['region'],
                info['created_date'],
                info['object_count'],
                info['size_bytes']
            )

        print("=" * 120)

        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print("\nğŸ“Š ã‚µãƒãƒªãƒ¼")
        print("=" * 120)
        print(f"ç·ãƒã‚±ãƒƒãƒˆæ•°:         {len(bucket_info_list):,}")
        print(f"ç·ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°:     {total_objects:,}")
        print(f"ç·ãƒ‡ãƒ¼ã‚¿é‡:           {format_size(total_size)} ({total_size:,} bytes)")

        # åœ§ç¸®ç‡ã‚’ä»®å®šã—ã¦æ¨å®š
        estimated_compressed = int(total_size * 0.7)  # 70%ã«åœ§ç¸®ã•ã‚Œã‚‹ã¨ä»®å®š
        print(f"åœ§ç¸®å¾Œæ¨å®šã‚µã‚¤ã‚º:     {format_size(estimated_compressed)} ï¼ˆåœ§ç¸®ç‡70%ã¨ä»®å®šï¼‰")

        # Dropboxå®¹é‡ã¨ã®æ¯”è¼ƒ
        dropbox_available = 1.5 * 1024 * 1024 * 1024 * 1024  # 1.5TB
        print(f"Dropboxç©ºãå®¹é‡:      {format_size(dropbox_available)}")

        if estimated_compressed <= dropbox_available:
            print(f"âœ… Dropboxå®¹é‡ã¯ååˆ†ã§ã™ï¼ˆä½™è£•: {format_size(dropbox_available - estimated_compressed)}ï¼‰")
        else:
            shortage = estimated_compressed - dropbox_available
            print(f"âš ï¸  Dropboxå®¹é‡ãŒä¸è¶³ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆä¸è¶³: {format_size(shortage)}ï¼‰")

        print(f"\n10GBè¶…ã®ãƒã‚±ãƒƒãƒˆ:     {large_buckets}å€‹ ï¼ˆåˆ†å‰²ãŒå¿…è¦ï¼‰")

        print("=" * 120)

        # JSONå‡ºåŠ›
        output_data = {
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total_buckets': len(bucket_info_list),
                'total_objects': total_objects,
                'total_size_bytes': total_size,
                'total_size_human': format_size(total_size),
                'estimated_compressed_bytes': estimated_compressed,
                'estimated_compressed_human': format_size(estimated_compressed),
                'large_buckets_count': large_buckets
            },
            'buckets': bucket_info_list
        }

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ è©³ç´°æƒ…å ±ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")

        logger.info("ãƒã‚±ãƒƒãƒˆæƒ…å ±ã®åé›†ãŒå®Œäº†ã—ã¾ã—ãŸ")

    except KeyboardInterrupt:
        print("\n\nâš ï¸  å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
        logger.warning("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        log_exception(logger, "äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", e)
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        print("è©³ç´°ã¯ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)


if __name__ == '__main__':
    main()
